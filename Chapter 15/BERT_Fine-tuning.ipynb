{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_Fine-tuning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNi305IXOQdqWlprJv1xSqT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# BERT 학습을 위한 전처리"],"metadata":{"id":"O9ViHPQHS2Zi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NwovhlJCSwAA"},"outputs":[],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","sentence1 = \"What a beautiful day!\"\n","sentence2 = \"Nvidia Titan XP has 12GB of VRAM\"\n","\n","# 1. 토큰화 결과\n","print(sentence1, '토큰화 결과:', tokenizer.tokenize(sentence1))\n","print(sentence2, '토큰화 결과:', tokenizer.tokenize(sentence2))"]},{"cell_type":"code","source":["# 2. BERT 모형 입력 생성\n","inputs = tokenizer([sentence1, sentence2], padding=True)\n","print('BERT 입력:', inputs)"],"metadata":{"id":"RQCXcd0-S6c1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. 두 문장으로 이루어진 시퀀스에 대한 BERT 모형 입력 생성\n","inputs = tokenizer(sentence1, sentence2, padding=True)\n","print('두 문장 시퀀스에 대한 BERT 입력:', inputs)"],"metadata":{"id":"5_Kc5YNRS7pM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 트랜스포머의 트레이너를 이용한 미세조정학습\n","\n","**NLTK 영화리뷰 데이터 준비**"],"metadata":{"id":"I-3C6IhKS959"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import movie_reviews\n","from sklearn.model_selection import train_test_split # sklearn에서 제공하는 split 함수를 사용\n","import numpy as np\n","\n","nltk.download('movie_reviews')\n","fileids = movie_reviews.fileids() # movie review data에서 file id를 가져옴\n","reviews = [movie_reviews.raw(fileid) for fileid in fileids] # file id를 이용해 raw text file을 가져옴\n","categories = [movie_reviews.categories(fileid)[0] for fileid in fileids] \n","\n","# label을 0, 1의 값으로 변환\n","label_dict = {'pos':1, 'neg':0}\n","y = [label_dict[c] for c in categories]\n","\n","X_train, X_test, y_train, y_test = train_test_split(reviews, y, test_size=0.2, random_state=7)\n","\n","print('Train set count: ', len(X_train))\n","print('Test set count: ', len(X_test))"],"metadata":{"id":"ax1c40_BTABI"},"execution_count":null,"outputs":[]}]}