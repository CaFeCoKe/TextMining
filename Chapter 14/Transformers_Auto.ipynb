{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformers_Auto.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNgD0QqpWY50oAC3BY/19xv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 자동 클래스를 이용한 토크나이저와 모형의 사용\n","\n","**두 문장의 의미적 유사도 비교**"],"metadata":{"id":"AG8NdqWrIsPy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"32v8omSVITj2"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","# Auto Classes를 이용해 사전학습된 내용에 맞는 토크나이저와 모형을 자동으로 설정\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\")"],"metadata":{"id":"XZh6rtXTIuht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gj2iDKpyK_MR","executionInfo":{"status":"ok","timestamp":1656752981609,"user_tz":-540,"elapsed":13,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"9cb35275-bb35-41db-8a79-f6eb18559df0"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"bert-base-cased-finetuned-mrpc\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.20.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NwtUqDBMK_mT","executionInfo":{"status":"ok","timestamp":1656752981609,"user_tz":-540,"elapsed":12,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"d75b25cc-681b-4a83-f23e-3002bc008312"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# 의미적으로 유사한 두 문장을 선언\n","input_sentence = \"She angered me with her inappropriate comments, rumor-spreading, and disrespectfulness at the formal dinner table\"\n","target_sequence = \"She made me angry when she was rude at dinner\"\n","\n","# 토큰화\n","tokens = tokenizer(input_sentence, target_sequence, return_tensors=\"pt\")\n","# 모형으로 결과를 예측\n","logits = model(**tokens).logits\n","# 소프트맥스를 이용해 결과값을 클래스에 대한 확률로 변환\n","results = torch.softmax(logits, dim=1).tolist()[0]\n","\n","for i, label in enumerate(['no', 'yes']):\n","    print(f\"{label}: {int(round(results[i] * 100))}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uBF_B7HKT0D","executionInfo":{"status":"ok","timestamp":1656752981610,"user_tz":-540,"elapsed":11,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"ad59aeb7-32c7-4974-d12c-4c50fcf7f4a3"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["no: 29%\n","yes: 71%\n"]}]},{"cell_type":"code","source":["target_sequence = \"The boy quickly ran across the finish line, seizing yet another victory\"\n","tokens = tokenizer(input_sentence, target_sequence, return_tensors=\"pt\")\n","logits = model(**tokens).logits\n","results = torch.softmax(logits, dim=1).tolist()[0]\n","\n","for i, label in enumerate(['no', 'yes']):\n","    print(f\"{label}: {int(round(results[i] * 100))}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0IYrBaKI0Mg","executionInfo":{"status":"ok","timestamp":1656752981895,"user_tz":-540,"elapsed":290,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"b2b24399-6825-4650-8964-c354de75064f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["no: 95%\n","yes: 5%\n"]}]},{"cell_type":"markdown","source":["**NLTK 영화리뷰 감정분석 학습**"],"metadata":{"id":"Z4jwaNxNJTcO"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import movie_reviews\n","from sklearn.model_selection import train_test_split # sklearn에서 제공하는 split 함수를 사용\n","import numpy as np\n","\n","nltk.download('movie_reviews')\n","fileids = movie_reviews.fileids() # movie review data에서 file id를 가져옴\n","reviews = [movie_reviews.raw(fileid) for fileid in fileids] # file id를 이용해 raw text file을 가져옴\n","categories = [movie_reviews.categories(fileid)[0] for fileid in fileids] \n","\n","# label을 0, 1의 값으로 변환\n","label_dict = {'pos':1, 'neg':0}\n","y = np.array([label_dict[c] for c in categories])\n","\n","X_train, X_test, y_train, y_test = train_test_split(reviews, y, test_size=0.2, random_state=7)\n","print('Train set count: ', len(X_train))\n","print('Test set count: ', len(X_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4mcARm2JNhR","executionInfo":{"status":"ok","timestamp":1656752981896,"user_tz":-540,"elapsed":10,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"4ff809e2-dbc0-4276-ab57-a4565710dcd1"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Train set count:  1600\n","Test set count:  400\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Package movie_reviews is already up-to-date!\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","import torch.nn.functional as F\n","\n","# cuda를 이용한 GPU 연산이 가능하면 cuda를 사용하고, 아니면 cpu를 사용\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","# Auto Classes를 이용해 사전학습된 내용에 맞는 토크나이저와 모형을 자동으로 설정\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n","\n","# 모델을 gpu로 옮겨서 연산을 준비\n","model = model.to(device)\n","\n","batch_size = 10 # 모형으로 한번에 예측할 데이터의 수\n","y_pred = [] # 전체 예측결과를 저장\n","\n","num_batch = len(y_test)//batch_size\n","\n","for i in range(num_batch):\n","    inputs = tokenizer(X_test[i*batch_size:(i+1)*batch_size], truncation=True, padding=True, return_tensors=\"pt\")\n","    # 토큰화 결과를 GPU로 이동\n","    inputs = inputs.to(device)\n","    # 모형으로 결과를 예측\n","    logits = model(**inputs).logits\n","    # 결과값을 클래스에 대한 확률로 변환\n","    pred = F.softmax(logits, dim=-1)\n","    # 예측결과를 CPU로 가져와서 넘파이로 변환한 후, argmax로 확률이 가장 큰 클래스를 선택함\n","    results = pred.cpu().detach().numpy().argmax(axis=1)\n","    \n","    # 전체 예측결과에 추가\n","    y_pred.extend(results.tolist())\n","\n","# gpu 메모리를 비움\n","torch.cuda.empty_cache()\n","\n","score = sum(y_test == np.array(y_pred))/len(y_test)\n","print(\"NLTK 영화리뷰 감성분석 정확도:\", score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1kXYFogCJR_W","executionInfo":{"status":"ok","timestamp":1656752991994,"user_tz":-540,"elapsed":10103,"user":{"displayName":"CaFe CoKe","userId":"11886396836022920274"}},"outputId":"cbc399ec-7a2e-43d4-cb3f-92f4289a6a88"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["NLTK 영화리뷰 감성분석 정확도: 0.8425\n"]}]}]}